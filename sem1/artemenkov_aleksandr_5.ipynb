{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 5\n",
    "\n",
    "1. Найти $\\nabla f(x)$, если $f(x) = \\|Ax\\| - \\|x^TA\\|$\n",
    "1. Найти $\\nabla f(x), f''(x)$, если $f(x) = \\dfrac{-1}{1 + x^Tx}$\n",
    "1. Найти $f'(X)$, если $f(X) = \\det X$  \n",
    "Примечание: здесь под $f'(X)$ подразумевается оценка фунции $f(X)$ первого порядка в смысле разложения в ряд Тейлора:\n",
    "    $$f(X + \\Delta X) \\approx f(X) + \\mathbf{tr}(f'(X)^T \\Delta X)$$\n",
    "1. Найти $f''(X)$, если $f(X) = \\log \\det X$  \n",
    "Примечание: здесь под $f''(X)$ подразумевается оценка фунции $f(X)$ второго порядка в смысле разложения в ряд Тейлора:\n",
    "    $$f(X + \\Delta X) \\approx f(X) + \\mathbf{tr}(f'(X)^T \\Delta X) + \\frac{1}{2}\\mathbf{tr}(\\Delta X^T f''(X) \\Delta X)$$\n",
    "1. Найти градиент и гессиан функции $f : \\mathbb{R}^n \\to \\mathbb{R}$, $f(x) = \\log \\sum\\limits_{i=1}^m \\exp (a_i^Tx + b_i), \\;\\;\\;\\; a_1, \\ldots, a_m \\in \\mathbb{R}^n; \\;\\;\\;  b_1, \\ldots, b_m  \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "$$ f(x) = \\|Ax\\|-\\|x^TA\\|$$\n",
    "$$ f(x) = \\sqrt{(Ax, Ax)} - \\sqrt{(x^TA, x^TA)}$$\n",
    "$$ \\frac{\\partial}{\\partial x_i}f(x) = \\frac{1}{2\\sqrt{(Ax, Ax)}}\\frac{\\partial(Ax, Ax)}{\\partial x_i} - \\frac{1}{2\\sqrt{(x^TA, x^TA)}}\\frac{\\partial(x^TA, x^TA)}{\\partial x_i}$$\n",
    "$$ \\frac{\\partial}{\\partial x_i}f(x) = \\frac{1}{\\sqrt{(Ax, Ax)}}(\\frac{\\partial}{\\partial x_i}(Ax), Ax) - \\frac{1}{\\sqrt{(x^TA, x^TA)}}(\\frac{\\partial}{\\partial x_i}(x^TA), x^TA)$$\n",
    "$$[\\nabla f(x)]_i =  \\frac{\\partial}{\\partial x_i}f(x) = \\frac{1}{\\|Ax\\|}(A\\frac{\\partial x}{\\partial x_i}, Ax) - \\frac{1}{\\|x^TA\\|}(\\frac{\\partial x^T}{\\partial x_i}A, x^TA)$$\n",
    "\n",
    "Преобразуем, используя следующие равенства (матрица Грама единичная):\n",
    "$$(x, y ) = x^Ty = xy^T$$\n",
    "$$\\nabla f(x) = \\sum_i [\\nabla f(x)]_i \\frac{\\partial x}{\\partial x_i}$$\n",
    "$$\\sum_i \\frac{\\partial x}{\\partial x_i} \\frac{\\partial x^T}{\\partial x_i} =\\sum_i \\frac{\\partial x^T}{\\partial x_i} \\frac{\\partial x}{\\partial x_i} = I$$\n",
    "\n",
    "Так что:\n",
    "$$ \\nabla f(x) = \\sum_i \\frac{\\partial x}{\\partial x_i} \\left[\\frac{1}{\\|Ax\\|}\\left(\\frac{\\partial x^T}{\\partial x_i}A^T Ax\\right) - \\frac{1}{\\|x^TA\\|}\\left(\\frac{\\partial x^T}{\\partial x_i}AA^Tx\\right)\\right]$$\n",
    "$$ \\nabla f(x) = \\sum_i \\left[\\frac{1}{\\|Ax\\|}\\left(\\frac{\\partial x}{\\partial x_i}\\frac{\\partial x^T}{\\partial x_i}\\right)A^T Ax - \\frac{1}{\\|x^TA\\|}\\left(\\frac{\\partial x}{\\partial x_i}\\frac{\\partial x^T}{\\partial x_i}\\right)AA^Tx\\right]$$\n",
    "$$ \\nabla f(x) = \\left(\\sum_i \\frac{\\partial x}{\\partial x_i}\\frac{\\partial x^T}{\\partial x_i}\\right)\\left(\\frac{1}{\\|Ax\\|}A^T Ax - \\frac{1}{\\|x^TA\\|}AA^Tx\\right)$$\n",
    "$$ \\nabla f(x) = \\left(\\frac{A^T A}{\\|Ax\\|} - \\frac{AA^T}{\\|x^TA\\|}\\right)x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "$$f(x) = \\dfrac{-1}{1 + x^Tx}$$\n",
    "\n",
    "$$ [\\nabla f(x)]_i = \\frac{\\partial}{\\partial x_i}f(x) = \\frac{2}{(1+x^Tx)^2}\\frac{\\partial x^T}{\\partial x_i}x$$\n",
    "\n",
    "$$ \\nabla f(x) = \\sum_i \\frac{\\partial x}{\\partial x_i} \\left[ \\frac{2}{(1+x^Tx)^2}\\frac{\\partial x^T}{\\partial x_i}x\\right] = \\sum_i \\left(\\frac{\\partial x}{\\partial x_i}\\frac{\\partial x^T}{\\partial x_i}\\right)\\frac{2x}{(1+x^Tx)^2} = \\frac{2x}{(1+x^Tx)^2}$$\n",
    "\n",
    "Запишем гессиан как \"сумму\" столбцов:\n",
    "$$f''(x) = \\frac{\\partial (\\nabla f(x))}{\\partial x^T}= \\sum_i \\frac{\\partial(\\nabla f(x))}{\\partial x_i}\\frac{\\partial x^T}{\\partial x_i}$$\n",
    "\n",
    "$$\\frac{\\partial(\\nabla f(x))}{\\partial x_i} = \\frac{2}{(1+x^Tx)^2} \\frac{\\partial x}{\\partial x_i} - \\frac{8x}{(1+x^Tx)^3}\\frac{\\partial x^T}{\\partial x_i}x = \\left(\\frac{2}{(1+x^Tx)^2} - \\frac{8xx^T}{(1+x^Tx)^3}\\right)\\frac{\\partial x}{\\partial x_i} = \\left(\\frac{2}{(1+x^Tx)^2} - \\frac{8x^Tx}{(1+x^Tx)^3}\\right)\\frac{\\partial x}{\\partial x_i} $$\n",
    "\n",
    "$$f''(x) = \\sum_i \\left(\\frac{2}{(1+x^Tx)^2} - \\frac{8x^Tx}{(1+x^Tx)^3}\\right)\\frac{\\partial x}{\\partial x_i}\\frac{\\partial x^T}{\\partial x_i} = \\left(\\frac{2}{(1+x^Tx)^2} - \\frac{8x^Tx}{(1+x^Tx)^3}\\right) \\left( \\sum_i \\frac{\\partial x}{\\partial x_i}\\frac{\\partial x^T}{\\partial x_i}\\right)$$\n",
    "$$f''(x) = \\left(\\frac{2}{(1+x^Tx)^2} - \\frac{8x^Tx}{(1+x^Tx)^3}\\right) I$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3\n",
    "  \n",
    " $$\\newcommand{tr}[1]{\\mathbf{tr}\\left[#1\\right]}$$\n",
    " $$\\newcommand{dp}[2]{\\left\\langle #1, #2\\right\\rangle}$$\n",
    " \n",
    " Не очень понял, зачем надо преобразовывать так:\n",
    " $$X + \\Delta X = X^{\\frac{1}{2}} (I + X^{-\\frac{1}{2}}\\Delta X X^{-\\frac{1}{2}})X^{\\frac{1}{2}}$$\n",
    " \n",
    " Всё, чем пользуемся, что при малой $\\|\\Delta X\\|$ малы собственные числа (что, кстати, требует отдельного доказательства, проведённого ниже) матрицы $X^{-\\frac{1}{2}}\\Delta X X^{-\\frac{1}{2}}$, можно так же сделать маленькими и собственные числа $X^{-1}\\Delta X$.  Можем делать так с тем же успехом:\n",
    " \n",
    "  $$X + \\Delta X = X (I + X^{-1}\\Delta X)$$\n",
    "\n",
    " Наверно, так делать надо, но при заданной строгости рассуждения проходят и так, что странно. На всякий случай, доказал, что выполнено (для комплекснозначных матриц тоже):\n",
    " $$\\sum_i |\\lambda_i|^2 \\le \\sum_{i, j}|a_{ij}|^2 = \\tr{AA^*} = \\|A\\|^2$$\n",
    " \n",
    " Перейдём в базис (ортонормированный) Шура, $U$ -- верхнетреугольная с собственными значениями на диагонали (по построению):\n",
    " $$ A = Q U Q^{-1}, \\; Q^{-1} = Q^* \\quad \\Longrightarrow \\quad U = Q^{*}AQ$$\n",
    " $$ \\sum_i |\\lambda_i|^2 = \\tr{U\\overline{U}} = \\tr{Q^{*}AQ\\overline{Q^{*}}\\overline{A}\\overline{Q})} = \\tr{Q^{*}QA\\overline{A}\\overline{Q^*Q}} = \\tr{A\\overline{A}}$$\n",
    " \n",
    " Покажем, что:\n",
    " $$ \\tr{A\\overline{A}} \\le \\tr{AA^*}$$\n",
    " \n",
    " $$ \\sum_{i, j=1}A_{ij}\\overline{A_{ji}} \\le \\sum_{i, j = 1}A_{ij}\\overline{A_{ij}}$$\n",
    "  \n",
    "$$ 0 \\le \\sum_{i < j}\\left(A_{ij}\\overline{A_{ij}} -A_{ij}\\overline{A_{ji}} -\\overline{A_{ij}}A_{ji}  + A_{ji}\\overline{A_{ji}}\\right)$$\n",
    "\n",
    "$$ 0 \\le \\sum_{i < j}\\left(A_{ij}(\\overline{A_{ij}} - \\overline{A_{ji}})-A_{ji}(\\overline{A_{ij}} - \\overline{A_{ji}})\\right)$$\n",
    "\n",
    "$$ 0 \\le \\sum_{i < j}\\left((A_{ij}-A_{ji})(\\overline{A_{ij}} - \\overline{A_{ji}})\\right)$$\n",
    "\n",
    "$$ 0 \\le \\sum_{i < j}\\left((A_{ij}-A_{ji})\\overline{(A_{ij} - A_{ji}})\\right)$$\n",
    "\n",
    "$$ 0 \\le \\sum_{i < j}|A_{ij}-A_{ji}|^2$$\n",
    "\n",
    "Выполнено. Причём равенство достигается при $A = A^T$. Так что выбирая $\\Delta X$ с достаточно малыми элементами, получим $X^{-1} \\Delta X$ с маленькой нормой и маленькими собственными числами. Покажем, что формула для матричного \"Тейлора\" вообще работает. Пусть $f(X): \\; \\mathbb{R}^{n \\times m} \\rightarrow \\mathbb{R}$. Тогда по определению: $\\newcommand{part}[2]{\\frac{\\partial #1}{\\partial #2}}$\n",
    "\n",
    "\n",
    "$$[f'(X)]_{ij} = \\part{f}{x_{ij}}$$\n",
    "\n",
    "Раскладывая по частным производным как дифференцируемую функцию многих переменных:\n",
    "\n",
    "$$ f(X) = g(x_{11}, \\dotsc, x_{1m},\\dotsc, x_{n1}, \\dotsc, x_{nm})$$\n",
    "$$ f(X + \\Delta X) = g(x_{11} + \\Delta x_{11}, \\dotsc, x_{1m} + \\Delta x_{1m},\\dotsc, x_{n1} + \\Delta x_{n1}, \\dotsc, x_{nm} + \\Delta x_{nm}) = $$\n",
    "$$ = g(x_{11}, \\dotsc, x_{1m},\\dotsc, x_{n1}, \\dotsc, x_{nm}) + \\part{g}{x_{11}}\\Delta x_{11} + \\dotsc + \\part{g}{x_{nm}}\\Delta x_{nm} + \\mathbf{o}(|\\Delta x_{11}| + \\dotsc + |\\Delta x_{nm}|) = $$ \n",
    "$$ = f(X) + \\sum_{ij}[f'(X)]_{ij}\\Delta x_{ij} + \\mathbf{o}(\\|\\Delta X\\|) = f(X) + \\tr{f'(X)^T \\Delta X} +  \\mathbf{o}(\\|\\Delta X\\|) $$\n",
    "\n",
    " В силу единственности разложения Тейлора для функций $\\mathbb{R} \\rightarrow \\mathbb{R}$ получаем единственность такого разложения для матричных функций.\n",
    "\n",
    "Теперь сама задачка:\n",
    " $$f(X) = \\det X$$\n",
    " \n",
    " \n",
    "  $$ f(X + \\Delta X) = \\det (X + \\Delta X) = \\det (X^{-1} (I + X^{-1}\\Delta X )) = \\det(X)\\det(I + X^{-1}\\Delta X) = $$\n",
    " $$= \\det X \\prod_i (1+\\lambda_i) \\simeq \\det X(1 + \\sum_i \\lambda_i) = \\det X + \\det X\\tr{X^{-1}\\Delta X} =$$\n",
    " \n",
    " Итак,\n",
    " \n",
    " $$ \\det (X + \\Delta X) \\simeq \\det X + \\dp{X^{-1}\\det X}{\\Delta X} +  \\mathbf{o}(\\|\\Delta X\\|)$$\n",
    " $$ \\det (X + \\Delta X) \\simeq \\det X + \\dp{f'(X)}{\\Delta X} +  \\mathbf{o}(\\|\\Delta X\\|)$$\n",
    " \n",
    " Откуда: \n",
    " \n",
    " $$ f'(X) = X^{-1}\\det X $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "$f(X) = \\log \\det X$ \n",
    "\n",
    "Введём обозначение:  $\\newcommand{dpart}[3]{\\frac{\\partial^2 #1}{\\partial #2 \\partial #3}}$\n",
    "$$ [f''(X)]_{ijkl} = \\dpart{f}{x_{ij}}{x_{kl}}$$\n",
    "\n",
    "Вообще, если снова записать формулу Тейлора, но теперь до второго порядка малости, то появится следующая сумма по смешанным производным:\n",
    "\n",
    "$$ f(X + \\Delta X)= g(x_{11}, \\dotsc, x_{1m},\\dotsc, x_{n1}, \\dotsc, x_{nm}) +  \\sum_{ij}[f'(X)]_{ij}\\Delta x_{ij} + \\sum_{ij}\\sum_{kl}\\dpart{f}{x_{ij}}{x_{kl}}\\Delta x_{ij} \\Delta x_{kl}+\\mathbf{o}(|\\Delta x_{11}|^2 + \\dotsc + |\\Delta x_{nm}|^2) = $$\n",
    "\n",
    "$$ = f(X) +\\tr{f'(X)^T \\Delta X} + \\sum_{ijkl} [f''(X)]_{ijkl} \\Delta x_{ij} \\Delta x_{kl} + \\mathbf{o}(\\|\\Delta X\\|^2)$$\n",
    "\n",
    "Если же расписать, то, что предлагается, то получим, что $f''(X)$ -- матрица, так что это две по-разному определённые вторые производные:\n",
    "\n",
    "$$f(X + \\Delta X) \\approx f(X) + \\mathbf{tr}(f'(X)^T \\Delta X) + \\frac{1}{2}\\mathbf{tr}(\\Delta X^T f''(X) \\Delta X)$$\n",
    "\n",
    "Будем использовать определение через ряд Тейлора, не хочется брать тензорную производную $\\part{X^{-1}}{x_{ij}}$ без необходимости. До этого момента вывод дословно повторяет действия с пары:\n",
    "\n",
    "$$\\log\\det\\left[ X+ \\Delta X\\right] = \\log\\det X + \\sum\\limits_{i=1}^n \\log(1 + \\lambda_i)$$\n",
    "\n",
    "Теперь учтём и слагаемые второго порядка малости:\n",
    "\n",
    "$$\\log\\det\\left[ X+ \\Delta X\\right] \\approx \\log\\det X + \\sum\\limits_{i=1}^n \\lambda_i - \\frac{1}{2}\\sum\\limits_{i=1}^n \\lambda_i^2$$\n",
    "\n",
    "Аналогично 3 задаче можно показать, что для квадратных матриц:\n",
    "\n",
    "$$ \\sum_i \\lambda_i^2 = \\tr{A^2}$$\n",
    "\n",
    "Так что (именно так, без транспонирования): \n",
    "\n",
    "$$ \\sum_i \\lambda_i^2 = \\tr{[X^{-1}\\Delta X]^2} = \\tr{X^{-2}\\Delta X^2}$$\n",
    "\n",
    "Если теперь в определении считать, что $\\Delta X = \\Delta X^T$ -- симметричная, то из равенства двух формул получим:\n",
    "\n",
    "$$ f''(X) = -X^{-2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "$f : \\mathbb{R}^n \\to \\mathbb{R}$, $f(x) = \\log \\sum\\limits_{i=1}^m \\exp (a_i^Tx + b_i), \\;\\;\\;\\; a_1, \\ldots, a_m \\in \\mathbb{R}^n; \\;\\;\\;  b_1, \\ldots, b_m  \\in \\mathbb{R}$\n",
    "\n",
    "Снова используем равенства:\n",
    "$$\\nabla f(x) = \\sum_i [\\nabla f(x)]_i \\part{x}{x_i} \\quad \\Longrightarrow \\quad \\nabla^T f(x) = \\sum_i [\\nabla f(x)]_i \\part{x^T}{x_i} $$\n",
    "$$\\sum_i \\frac{\\partial x}{\\partial x_i} \\frac{\\partial x^T}{\\partial x_i} =\\sum_i \\frac{\\partial x^T}{\\partial x_i} \\frac{\\partial x}{\\partial x_i} = I$$\n",
    "\n",
    "$$[\\nabla f(x)]_i = \\frac{\\partial (f(x))}{\\partial x_i} = \\frac{ \\sum\\limits_{k=1}^m\\exp (a_k^Tx + b_k)\\part{(a_k^Tx + b_k)}{x_i}}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)} = \\frac{ \\sum\\limits_{k=1}^m\\exp (a_k^Tx + b_k)a_k^T\\part{x}{x_i}}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)} = \\frac{ \\sum\\limits_{k=1}^m a_k^T \\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)} \\part{x}{x_i} $$\n",
    "\n",
    "$$\\nabla^T f(x) = \\sum_i [\\nabla f(x)]_i \\part{x^T}{x_i} = \\sum_i \\frac{ \\sum\\limits_{k=1}^m a_k^T \\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)}\\part{x}{x_i} \\part{x^T}{x_i} = \\frac{ \\sum\\limits_{k=1}^m a_k^T \\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)} \\sum_i \\left( \\part{x}{x_i} \\part{x^T}{x_i} \\right)$$\n",
    "\n",
    "$$\\nabla f(x) = \\frac{ \\sum\\limits_{k=1}^m a_k \\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)}$$\n",
    "\n",
    "Запишем гессиан как \"сумму\" столбцов:\n",
    "$$f''(x) =\\part{(\\nabla f(x))}{x^T}= \\sum_i \\part{(\\nabla f(x))}{x_i}\\part{x^T}{x_i}$$\n",
    "\n",
    "$$\\part{(\\nabla f(x))}{x_i} = \\frac{ \\sum\\limits_{k=1}^m a_k\\exp (a_k^Tx + b_k)\\part{(a_k^Tx + b_k)}{x_i}}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)} -  \\frac{\\left[ \\sum\\limits_{k=1}^m a_k\\exp (a_k^Tx + b_k)\\right] \\left[ \\sum\\limits_{n=1}^m \\exp (a_n^Tx + b_n)\\part{(a_n^Tx + b_n)}{x_i} \\right]}{ \\left[\\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)\\right]^2}$$\n",
    "\n",
    "$$\\part{(\\nabla f(x))}{x_i} = \\frac{ \\sum\\limits_{k=1}^m a_k a_k^T\\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)}\\part{x}{x_i} -  \\frac{\\left[ \\sum\\limits_{k=1}^m a_k\\exp (a_k^Tx + b_k)\\right] \\left[ \\sum\\limits_{n=1}^m a_n^T\\exp (a_n^Tx + b_n) \\right]}{ \\left[\\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)\\right]^2} \\part{x}{x_i}$$\n",
    "\n",
    "$$f''(x)= \\sum_i \\part{(\\nabla f(x))}{x_i}\\part{x^T}{x_i} =  \\sum_i \\left(\\frac{ \\sum\\limits_{k=1}^m a_k a_k^T\\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)}\\left(\\part{x}{x_i} \\part{x^T}{x_i} \\right)-  \\frac{\\left[ \\sum\\limits_{k=1}^m a_k\\exp (a_k^Tx + b_k)\\right] \\left[ \\sum\\limits_{n=1}^m a_n^T\\exp (a_n^Tx + b_n) \\right]}{ \\left[\\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)\\right]^2}\\left(\\part{x}{x_i} \\part{x^T}{x_i} \\right)\\right)$$\n",
    "\n",
    "Итак, \n",
    "\n",
    "$$ f''(x) = I\\left(\\frac{ \\sum\\limits_{k=1}^m a_k a_k^T\\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)}-  \\frac{\\left[ \\sum\\limits_{k=1}^m a_k\\exp (a_k^Tx + b_k)\\right] \\left[ \\sum\\limits_{n=1}^m a_n^T\\exp (a_n^Tx + b_n) \\right]}{ \\left[\\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)\\right]^2}\\right)$$\n",
    "\n",
    "\n",
    "$$ f''(x) = \\frac{ \\sum\\limits_{k=1}^m a_k a_k^T\\exp (a_k^Tx + b_k)}{ \\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)}-  \\frac{\\left[ \\sum\\limits_{k=1}^m a_k\\exp (a_k^Tx + b_k)\\right] \\left[ \\sum\\limits_{n=1}^m a_n^T\\exp (a_n^Tx + b_n) \\right]}{ \\left[\\sum\\limits_{k=1}^m \\exp (a_k^Tx + b_k)\\right]^2}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
